{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8923d736-6ba9-4c7b-8e28-f42256cb97a5",
   "metadata": {},
   "source": [
    "## Hi Dylan!\n",
    "Changes:<br>\n",
    "2025-07-15 - Adding looping through different `n` values, as discussed, and distribution plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71049a3d-ecc8-4f26-a195-f37ed9c5ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from itertools import starmap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy import signal\n",
    "\n",
    "# # for later ...\n",
    "# import statsmodels.api as sm\n",
    "# import statsmodels.formula.api as smf\n",
    "# from statsmodels.stats.multitest import fdrcorrection as fdr\n",
    "\n",
    "# This code below doesn't do anything important, \n",
    "# I just think it makes plots look nicer\n",
    "from matplotlib.font_manager import findfont, FontProperties\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"font.serif\"] = ['Georgia', 'Times New Roman',\n",
    "                               'Times', 'Cambria']\n",
    "font = findfont(FontProperties(family=['serif']))\n",
    "mpl.rcParams['mathtext.fontset'] = 'custom'\n",
    "mpl.rcParams['mathtext.rm'] = 'Georgia'\n",
    "mpl.rcParams['mathtext.it'] = 'Georgia:italic'\n",
    "mpl.rcParams['mathtext.bf'] = 'Georgia:bold'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02772fc8-5432-4605-adea-bf9841d599b3",
   "metadata": {},
   "source": [
    "## Loading in data\n",
    "\n",
    "You'll have to tell the computer where to look for data\n",
    "The address that directs the computer to a file is called a path\n",
    "\n",
    "example path (from a Windows computer):\n",
    "\"C:\\Users\\jmile3\\OneDrive - SCH\\resting_state\\corrected_spectra.csv\"\n",
    "\n",
    "On Windows, you can right click a file and \"Copy as path\" will show\n",
    "up as an option. Not sure how to do that on Mac but might be worth\n",
    "figuring out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b70be-f437-4371-9307-a0b648b86bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from tables\n",
    "# variables of interest (e.g., PAF, INT, variables that parameterize aperiodic activity, organizing metadata, etc.)\n",
    "\n",
    "# r\"C:\\Users\\jmile3\\OneDrive - SCH\\resting_state\\corrected_spectra.csv\"\n",
    "\n",
    "params_path = r\"INSERT FOLDER LOCATION WITH 'params_table.csv' HERE\"\n",
    "resid_path = r\"INSERT FOLDER LOCATION WITH 'corrected_spectra.csv' HERE\"\n",
    "\n",
    "params_path = r\"C:\\Users\\jmile3\\OneDrive - SCH\\resting_state\\params_table.csv\"\n",
    "resid_path = r\"C:\\Users\\jmile3\\OneDrive - SCH\\resting_state\\corrected_spectra.csv\"\n",
    "\n",
    "params_table = pd.read_csv(params_path,dtype={\"age\":float})\n",
    "# power spectra - only needed in this case for confirming which data are well fit and filtering out bad fits\n",
    "resid_table = pd.read_csv(resid_path,index_col=False,dtype={\"ID\":str,\"age\":float})\n",
    "\n",
    "# initialize a random number generator for use later\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# increase number below to see more values in the table\n",
    "display(params_table.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef371d8-3803-4a6e-9321-1080ff946fc8",
   "metadata": {},
   "source": [
    "## Doing some filtering\n",
    "The code below filters data so that it is a bit nicer to work with from a statistics/math standpoint. Primarily, this means:\n",
    "1. getting rid of data that weren't fit well\n",
    "2. applying a Gaussian-weighted average to the different timeseries of data (which are the columns of the matrix in the way the table is set up here)\n",
    "3. adding an annotation for where in the hierarchy the data sit (S (sensory) or A (association)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9793efa-8580-432a-abea-c4ac5e2e5c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of poor model fits\n",
    "params_table[\"keep\"] = np.squeeze(np.abs(resid_table.loc[:,['0.5']])<0.2)\n",
    "params_table.loc[np.logical_not(params_table.keep),['PAF','INT']] = np.nan\n",
    "\n",
    "# making a copy of the original data for modification\n",
    "df = params_table.copy(deep=True)\n",
    "\n",
    "# smooth with a small-window Gaussian weighted average\n",
    "# window is centered, so an odd number makes most sense\n",
    "win = 5\n",
    "std = 1 # dictates window width i.e., influence of surrounding points\n",
    "# group data by these variables - unique combinations will form unique groupings\n",
    "grpvars = [\"ID\",\"age\",\"region\"]\n",
    "df = df.groupby(by=grpvars,sort=False).rolling(window=win,center=True, win_type=\"gaussian\", min_periods=1).mean(win,std).reset_index()\n",
    "# this just gets rid of an extra indexing/organizing column\n",
    "# should always work (so try/except probably not necessary)\n",
    "try:\n",
    "    df = df.drop(columns=\"level_3\")\n",
    "except:\n",
    "    pass\n",
    "# window fuction gets applied to all columns, but don't want these to change\n",
    "# replace with the original data\n",
    "df[[\"keep\",\"time\",\"ix\"]] = params_table[[\"keep\",\"time\",\"ix\"]]\n",
    "\n",
    "\n",
    "# sensorimotor and unimodal cortex vs multi/transmodal association cortex\n",
    "unimod = [\"Postcentral_gyrus\",\"Precentral_gyrus\",\"Superior_temporal_gyrus\"] # sensorimotor/unimodal regions\n",
    "transmod = [\"Middle_frontal_gyrus\", \"Middle_temporal_gyrus\", \"Supramarginal_gyrus\"] # association/transmodal regions\n",
    "df.loc[df.region.isin(unimod),'ctx'] = \"S\" # apparently switching to S-A axis notation...\n",
    "df.loc[df.region.isin(transmod),'ctx'] = \"A\"\n",
    "\n",
    "regions = df.region.unique()\n",
    "print(\"Regions in dataset:\")\n",
    "for reg in regions:\n",
    "    print(\"    \",reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d7f7e8-c126-4f37-8b9e-db5364c6ed01",
   "metadata": {},
   "source": [
    "## Defining some helper functions\n",
    "Functions are useful for doing operations that you expect will need to be done over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c675dd-9403-4a47-9019-d3535fcf2951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def n_unique(seq):\n",
    "    # nunique method will exist with rolling in pandas 3.0\n",
    "    return(len(seq[seq.notna()].unique()))\n",
    "\n",
    "def genvalidseqs(in_df,col_str,n,n_valid,min_diff,min_uni):\n",
    "    '''\n",
    "    find all valid n-length sequences/ranges for a given df and column\n",
    "    \n",
    "    valid sequences/ranges are defined by:\n",
    "        1) having at least n_valid non-nan elements in an n-length window\n",
    "        2) having a range of at least min_diff (window max-min >= min_diff)\n",
    "        3) having at least min_uni unique elements in the window\n",
    "\n",
    "    currently, returns a list of lists\n",
    "    each individual list is a range of n values that ends with the valid indices\n",
    "    that meet the above criteria\n",
    "\n",
    "    may make more sense to just return the ending indices, and generate the list\n",
    "    of lists after the fact with the starmap operation used in the return?\n",
    "    \n",
    "    '''\n",
    "    seq_series = in_df[col_str]\n",
    "\n",
    "    # calculate the rolling sum of values that are not nan\n",
    "    countnas = seq_series.notna().rolling(window=n,center=False,min_periods=n_valid).sum()\n",
    "    # create a boolean array of values that are above a threshold\n",
    "    valid_counts = countnas>=n_valid\n",
    "    \n",
    "    # calculate the range of values in the window\n",
    "    maxs = seq_series.rolling(window=n,center=False,min_periods=1).max(skipna=True)\n",
    "    # pandas is telling me it can't use skipna for min? maybe if I update to 2.3...\n",
    "    mins = seq_series.rolling(window=n,center=False,min_periods=1).min(numeric_only=True)\n",
    "    # create a boolean array of values that are above a threshold\n",
    "    valid_ranges = (maxs-mins)>=min_diff\n",
    "    \n",
    "    # calculate the range of values in the window\n",
    "    num_diffs = seq_series.rolling(window=n,center=False,min_periods=1).apply(n_unique)\n",
    "    # create a boolean array of values that are above a threshold\n",
    "    valid_unis = num_diffs>=min_uni\n",
    "    # union of boolean masks as array of indices\n",
    "    valid_ends = in_df.index[valid_counts & valid_ranges & valid_unis].to_numpy() \n",
    "    # prevent negative values\n",
    "    return valid_ends[valid_ends>=n]\n",
    "    \n",
    "    # better to return as iterator?\n",
    "    # return list(starmap(np.arange,np.array((endixs-n,endixs)).T))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c34376d-f085-40c8-a2f4-3c3cd2f749dd",
   "metadata": {},
   "source": [
    "Your goal is to set the values below:\n",
    "```\n",
    "n\n",
    "min_diff\n",
    "min_uni\n",
    "```\n",
    "\n",
    "`n` is the number of consecutive indices needed in a sequence for calculating a correlation\n",
    "`min_diff` is the range that values should span to count as a valid sequence\n",
    "`min_uni` is the minimum number of unique values that should occur for a sequence to be considered valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fddd4ed-176c-4479-bad2-ed0d8543846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# figure out these values !!!\n",
    "n = 20\n",
    "min_diff = 2\n",
    "min_uni = 5\n",
    "##################\n",
    "\n",
    "# proportion of values that cannot be nan\n",
    "n_valid = int(np.floor(n*2/3))\n",
    "\n",
    "# randomly pick an ID\n",
    "ID = rng.choice(df.ID.unique())\n",
    "print(ID)\n",
    "# filter table so you're just looking at data from\n",
    "# randomly chosen ID\n",
    "subdf = df.loc[df.ID == ID,:].reset_index(drop=True) \n",
    "# randomly pick a region from that ID\n",
    "reg = rng.choice(subdf.region[subdf.ctx==\"A\"])\n",
    "print(reg)\n",
    "# now just get data from that ID's region\n",
    "reg_df = subdf.loc[subdf.region == reg,:].reset_index(drop=True)\n",
    "\n",
    "endixs = genvalidseqs(reg_df,\"PAF\",n,n_valid,min_diff,min_uni)\n",
    "print(len(endixs))\n",
    "\n",
    "all_ixs = list(starmap(np.arange,np.array((endixs-n,endixs)).T))\n",
    "\n",
    "##########\n",
    "# plotting\n",
    "##########\n",
    "\n",
    "# randomly grab one of the possible valid indices\n",
    "plot_ixs = np.array(all_ixs[rng.integers(0,high=len(all_ixs))])\n",
    "\n",
    "# generate a figure\n",
    "fig,ax = plt.subplots(figsize=(4,3),tight_layout=True)\n",
    "    \n",
    "ax.plot(reg_df.time[plot_ixs],reg_df.PAF[plot_ixs])\n",
    "ax.set_ylim([np.percentile(df.PAF[df.PAF.notna()],0.5), \n",
    "             np.percentile(df.PAF[df.PAF.notna()],99.5)])\n",
    "ax.set_ylabel(\"PAF (Hz)\")\n",
    "ax.set_xlabel(\"Time (sec)\")\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(reg_df.time[plot_ixs],reg_df.INT[plot_ixs],\"r:\")\n",
    "ax2.set_ylim([np.percentile(df.INT[df.INT.notna()],0.5), \n",
    "              np.percentile(df.INT[df.INT.notna()],99.5)])\n",
    "ax2.set_ylabel(\"INT (ms)\",color=\"red\")\n",
    "ax2.set_xlabel(\"Time (sec)\")\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# NOTE:\n",
    "# y limits are set based on 1st and 99th percentiles\n",
    "# these can be changed to zoom in \n",
    "# (can't zoom out much, set to contain 99% of data)\n",
    "# can also set them manually (PAF can be between 3 and 14, INT around 10 to 100)\n",
    "\n",
    "# OTHER NOTE:\n",
    "# might see gaps in data - these are periods when there are no valid data\n",
    "# this almost always means no alpha oscillation was detectable\n",
    "\n",
    "# have to mask out nans to do correlations, this excludes across df index (row)\n",
    "nanmask = reg_df.loc[plot_ixs,[\"PAF\",\"INT\"]].notna().all(axis=1)\n",
    "corr = np.round(stats.pearsonr(reg_df.INT[plot_ixs[nanmask]],reg_df.PAF[plot_ixs[nanmask]]).statistic,3)\n",
    "\n",
    "ax2.annotate(\"$R$ = \"+str(corr),xy=(0.05, 1.025), xycoords=\"axes fraction\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb71ac0d-f988-4f64-8464-c4e810d2bb71",
   "metadata": {},
   "source": [
    "## Looping through different durations of data\n",
    "\n",
    "For simplicity, the cell below is the same as the one above, but with the important part inclosed in a `for loop`. <br>\n",
    "The value of `n` changes each loop *iteration*, and calculates correlations for `iters` random selections of data. <br>\n",
    "<br>\n",
    "*Note: Can optimize this code quite a bit, but won't have time to do that until next week. Sorry!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223896cf-9953-4352-b79d-0dd774250f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# figure out these values !!!\n",
    "n = 20 # this will soon change based on list below\n",
    "min_diff = 2\n",
    "min_uni = 5\n",
    "##################\n",
    "\n",
    "#### new variables #####\n",
    "# looping over this list of values for n\n",
    "n_list = [10, 20, 40, 80, 160]\n",
    "# 100 is pretty small, but code is too slow for more right now\n",
    "iters = 100 \n",
    "\n",
    "# generate a figure\n",
    "fig,ax = plt.subplots(nrows=1,ncols=len(n_list),figsize=(6,3),tight_layout=True)\n",
    "# keep track of plotting locations\n",
    "row = 0\n",
    "col = 0\n",
    "for n in n_list:\n",
    "    # create a container to store values in\n",
    "    n_corrs = [] # empty list\n",
    "    # proportion of values that cannot be nan\n",
    "    n_valid = int(np.floor(n*2/3))\n",
    "    print(n)\n",
    "    for it in range(iters):\n",
    "        # randomly pick an ID\n",
    "        ID = rng.choice(df.ID.unique()[df.ID.unique()!=\"71944e\"])\n",
    "        # filter table so you're just looking at data from\n",
    "        # randomly chosen ID\n",
    "        subdf = df.loc[df.ID == ID,:].reset_index(drop=True) \n",
    "        # randomly pick a region from that ID\n",
    "        reg = rng.choice(subdf.region.unique())\n",
    "        # now just get data from that ID's region\n",
    "        reg_df = subdf.loc[subdf.region == reg,:].reset_index(drop=True)\n",
    "        # generate the valid sequences for reg_df\n",
    "        endixs = genvalidseqs(reg_df,\"PAF\",n,n_valid,min_diff,min_uni)        \n",
    "        all_ixs = list(starmap(np.arange,np.array((endixs-n,endixs)).T))\n",
    "        # randomly pick one of the valid sequences\n",
    "        plot_ixs = np.array(all_ixs[rng.integers(0,high=len(all_ixs))])\n",
    "        # mask out nans\n",
    "        nanmask = reg_df.loc[plot_ixs,[\"PAF\",\"INT\"]].notna().all(axis=1)\n",
    "        # calculate correlation\n",
    "        corr = stats.pearsonr(reg_df.INT[plot_ixs[nanmask]],reg_df.PAF[plot_ixs[nanmask]]).statistic\n",
    "        # \"append\" (add) corr to the container we made\n",
    "        n_corrs.append(corr)\n",
    "        # end of the inner loop is here\n",
    "\n",
    "    ##########\n",
    "    # plotting\n",
    "    ##########\n",
    "\n",
    "    ax[col].hist(n_corrs,bins=np.linspace(-1,1,51),histtype='stepfilled',ec=[0.2,0.4,0.2,0.8],fc=[0.2,0.4,0.2,0.4])\n",
    "    ax[col].plot([0,0],[0,iters/6],\"k:\")\n",
    "    ax[col].set_title(\"n = \"+str(n))\n",
    "    # \"increment\" counter for columns (only 1 row for now)\n",
    "    col = col+1\n",
    "# show the plots (at the end - out of the loop)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
